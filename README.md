üè≠ Proyek Predictive Maintenance (PM) Mesin Industri
Proyek ini bertujuan untuk membangun model Machine Learning yang andal untuk memprediksi kegagalan mesin pada dataset AI4I 2020. Fokus utama adalah mencapai Recall tinggi dalam mendeteksi kegagalan (Kelas 1) sambil mengatasi masalah kritis data leakage dan class imbalance yang parah.

1: Preprocessing Data (Shared Pipeline)Blok ini adalah fondasi yang menyiapkan data, menangani imbalance, missing values, dan dimensionality sebelum diserahkan ke model.1. Feature Aggregation dan Data Leakage PreventionPenggabungan Data: Tiga dataset digabungkan (merge) setelah data time-series dari $\mathbf{df2}$ dan $\mathbf{df3}$ dirata-ratakan (agregasi) per ID mesin. Proses ini menghasilkan feature set tunggal dengan banyak nilai kosong (NaN).Leakage Prevention: Lima fitur biner kegagalan (TWF, HDF, dll.) dihapus dari $\mathbf{X}$ untuk memastikan model memprediksi kegagalan berdasarkan kondisi fisik dan bukan berdasarkan sinyal yang sudah terdeteksi.2. Train-Test Split dan Imbalance HandlingSplit Data: Data dibagi menjadi $80\%$ training dan $20\%$ testing menggunakan stratify=y untuk menjaga rasio kelas minoritas (kegagalan) yang sangat langka tetap proporsional di kedua set data, yang merupakan kunci untuk evaluasi yang adil.SMOTE: Teknik Synthetic Minority Over-sampling Technique (SMOTE) dimasukkan ke dalam ImbPipeline untuk oversampling kelas kegagalan pada data training, secara fisik menyeimbangkan dataset yang digunakan model untuk belajar.3. Preprocessing Pipeline (ColumnTransformer)Objek preprocessor adalah jantung dari transformasi data, yang hanya belajar dari data latih (X_train):KNNImputer (Imputasi Cerdas): Nilai NaN diisi berdasarkan rata-rata 5 sampel terdekat (k=5). Ini adalah peningkatan signifikan dari mean/median karena mempertahankan korelasi fitur.PCA (0.90): Fitur-fitur hasil agregasi (PCA features) menjalani reduksi dimensi. PCA mempertahankan $90\%$ variansi data asli, mengurangi jumlah fitur yang harus diproses model tanpa kehilangan informasi penting.StandardScaler & OneHotEncoder: Fitur inti diskalakan (distandardisasi), dan fitur kategorikal (Type) diubah menjadi format biner.
Model A: Implementasi XGBoost (Blok 2a & Inferensi)1. Pelatihan Model dan Class Weightingscale_pos_weight: Model xgb.XGBClassifier menggunakan class weight yang dihitung dari rasio kelas $0:1$ data latih. Bobot penalti yang sangat tinggi ini diberikan pada Kelas 1 (kegagalan), secara langsung memaksa model untuk memprioritaskan peningkatan Recall.Pipeline: Model digabungkan dengan preprocessor dan SMOTE dalam ImbPipeline dan dilatih.Hyperparameter: Pengaturan seperti n_estimators=500 dan learning_rate=0.03 digunakan untuk meningkatkan akurasi sekaligus mengontrol overfitting.2. Evaluasi dan Visualisasi KinerjaMetrik Kritis: Kinerja dilaporkan untuk set data Training dan Testing dengan fokus pada Recall dan F1-Score. Tingginya Recall pada set Testing menegaskan keberhasilan strategi penanganan imbalance.Confusion Matrix: Visualisasi ini  menampilkan jumlah kesalahan prediksi secara rinci. Tujuan utamanya adalah melihat nilai False Negatives (FN) (kegagalan yang terlewatkan) untuk memastikan model berhasil meminimalkannya.3. Inferensi Interaktif (Testing)Input Handling: Skrip meminta 6 fitur inti dari pengguna.Feature Completion: Karena pipeline mengharapkan semua fitur (termasuk hasil PCA), fitur agregasi yang hilang diisi dengan nilai rata-rata historis (mean) dari data latih. Ini adalah placeholder yang diperlukan agar pipeline dapat memproses input.Prediksi: Data input yang sudah lengkap dilewatkan ke model yang tersimpan (maintenance_pipeline_xgb_knn.pkl). Hasil akhir berupa klasifikasi (0 atau 1) dan probabilitas kegagalan ditampilkan, diikuti dengan saran tindakan.
Model B: Implementasi Random Forest (Blok 2b & Inferensi)1. Pelatihan Model dan Class Weightingclass_weight='balanced': Model RandomForestClassifier menggunakan penyesuaian bobot bawaan model untuk memberikan bobot yang lebih tinggi pada sampel kelas kegagalan, mirip dengan XGBoost tetapi dengan implementasi yang lebih sederhana (strategi bagging).Pipeline: Model dilatih menggunakan ImbPipeline yang sama (preprocessor $\rightarrow$ SMOTE $\rightarrow$ rf_model), memastikan perbandingan yang adil.2. Evaluasi dan Visualisasi KinerjaStabilitas: Hasil Random Forest berfungsi sebagai baseline yang stabil dan cepat. Evaluasi metriknya dibandingkan langsung dengan XGBoost untuk menentukan model mana yang memiliki kemampuan generalisasi terbaik (jika RF menghasilkan Recall yang lebih baik, ia yang dipilih).Confusion Matrix: Visualisasi ini  juga penting untuk mengonfirmasi jenis kesalahan yang dibuat oleh model Random Forest pada data Testing.3. Inferensi Interaktif (Testing)Proses Identik: Logika inferensi, termasuk pengisian fitur agregasi dengan placeholder mean, diulang menggunakan pipeline Random Forest yang tersimpan (maintenance_pipeline_rf_knn.pkl).Perbandingan: Hasil prediksi RF ini memungkinkan pengguna membandingkan keputusan dan tingkat kepercayaan (probabilitas) antara kedua model pada kondisi operasional mesin yang sama.
